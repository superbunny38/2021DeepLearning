{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2 Chap 5-순환 신경망(RNN).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1m_b70gUdXYDNzhM3d6AU8_u3jIiNSxDX",
      "authorship_tag": "ABX9TyPyCqlynGyNsVxRTbT75XOT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/superbunny38/2021DeepLearning/blob/main/2_Chap_5_%EC%88%9C%ED%99%98_%EC%8B%A0%EA%B2%BD%EB%A7%9D(RNN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "QXfvkLy0rx93"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "x2F0gmVOrV4H"
      },
      "outputs": [],
      "source": [
        "class RNN:\n",
        "  def __init__(self, Wx,Wh,b):#초기화\n",
        "    self.params = [Wx,Wh,b]#가중치 2개+편향 1개\n",
        "    self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]#기울기\n",
        "    self.cache = None#역전파 계산 시 사용하는 중간 데이터를 담을 곳\n",
        "  \n",
        "  def forward(self, x, h_prev):#순전파\n",
        "    Wx, Wh, b = self.params\n",
        "    t = np.matmul(h_prev, Wh)+np.matmul(x,Wx)+b#h_prev: 하나 앞의 RNN 계층으로부터 받은 입력\n",
        "    h_next = np.tanh(t)#h_next: 현 시각 RNN계층으로부터의 출력(다음 시각 계층으로의 입력)\n",
        "\n",
        "    self.cache = (x,h_prev, h_next)\n",
        "    return h_next\n",
        "  \n",
        "  def backward(self, dh_next):#역전파\n",
        "    Wx, Wh, b = self.params\n",
        "    x, h_prev, h_next = self.cache\n",
        "\n",
        "    dt = dh_next * (1-h_next ** 2)\n",
        "    db = np.sum(dt, axis = 0)\n",
        "    dWh = np.matmul(h_prev.T, dt)\n",
        "    dh_prev = np.matmul(dt,Wh.T)\n",
        "    dWx = np.matmul(x.T, dt)\n",
        "    dx = np.matmul(dt, Wx.T)\n",
        "\n",
        "    self.grads[0][...] = dWx\n",
        "    self.grads[1][...] = dWh\n",
        "    self.grads[2][...] = db\n",
        "\n",
        "    return dx, dh_prev"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeRNN:\n",
        "  def __init__(self, Wx, Wh, b, stateful = False):#stateful: 은닉상태를 인계받을지\n",
        "    #stateful == True: Time RNN 계층이 은닉 상태를 유지한다는 뜻; 아무리 긴 시계열 데이터라도 Time RNN 계층의 순전파를 끊지 않고 전파한다는 뜻\n",
        "    #stateful == False: 은닉 상태를 영행렬(모든 요소가 0인 행렬)로 초기화(무상태)\n",
        "    self.params = [Wx,Wh,b]\n",
        "    self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
        "    self.layers = None#다수의 RNN 계층을 리스트로 저장하는 용도\n",
        "\n",
        "    self.h, self.dh = None, None#h: forward() 메서드를 불렀을 때의 마지막 RNN 계층의 은닉 상태를 저장 dh: backward()를 불렀을 때 하나 앞 블록의 은닉 상태의 기울기를 저장\n",
        "    self.stateful = stateful\n",
        "\n",
        "  def set_state(self, h):#은닉 상태를 설정\n",
        "    self.h = h\n",
        "  \n",
        "  def reset_state(self):#은닉 상태 초기화\n",
        "    self.h = None\n",
        "\n",
        "  def forward(self, xs):#순전파(RNN계층의 순전파에서는 출력이 2개로 분기됨)\n",
        "    Wx, Wh, b = self.params#xs: T개 분량의 시계열 데이터를 하나로 모은 것\n",
        "    N, T, D = xs.shape#N: 미니배치 크기, D: 입력 벡터의 차원 수\n",
        "    D, H = Wx.shape\n",
        "\n",
        "    self.layers = []\n",
        "    hs = np.empty((N,T,H),dtype = 'f')\n",
        "\n",
        "    if not self.stateful or self.h is None:\n",
        "      self.h = np.zeros((N,H), dtype = 'f')#h: RNN 계층의 은닉 상태, 영행렬로 초기화\n",
        "\n",
        "  def backward(self, dhs):#역전파\n",
        "    Wx, Wh, b = self.params\n",
        "    N, T, H = dhs.shape\n",
        "    D, H = Wx.shape\n",
        "\n",
        "    dxs = np.empty((N,T, D), dtype = 'f')#가장 먼저 하류로 흘러보낼 기울기를 담을 그릇\n",
        "    dh = 0\n",
        "    grads = [0,0,0]\n",
        "    for t in reversed(range(T)):\n",
        "      layer = self.layers[t]\n",
        "      dx, dh = layer.backward(dhs[:,t,:]+dh)#합산된 기울기\n",
        "      dxs[:,t,:] = dx\n",
        "      \n",
        "      for i, grad in enumerate(layer.grads):\n",
        "        grads[i]+= grad#가중치 기울기를 합산\n",
        "    \n",
        "    for i, grad in enumerate(grads):\n",
        "      self.grads[i][...] = grad\n",
        "    self.dh = dh\n",
        "\n",
        "    return dxs"
      ],
      "metadata": {
        "id": "XmCYy0pgsOgv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#깃허브에서 가져옴\n",
        "# coding: utf-8\n",
        "from common.np import *  # import numpy as np (or import cupy as np)\n",
        "from common.layers import *\n",
        "from common.functions import sigmoid\n",
        "class TimeEmbedding:\n",
        "    def __init__(self, W):\n",
        "        self.params = [W]\n",
        "        self.grads = [np.zeros_like(W)]\n",
        "        self.layers = None\n",
        "        self.W = W\n",
        "\n",
        "    def forward(self, xs):\n",
        "        N, T = xs.shape\n",
        "        V, D = self.W.shape\n",
        "\n",
        "        out = np.empty((N, T, D), dtype='f')\n",
        "        self.layers = []\n",
        "\n",
        "        for t in range(T):\n",
        "            layer = Embedding(self.W)\n",
        "            out[:, t, :] = layer.forward(xs[:, t])\n",
        "            self.layers.append(layer)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        N, T, D = dout.shape\n",
        "\n",
        "        grad = 0\n",
        "        for t in range(T):\n",
        "            layer = self.layers[t]\n",
        "            layer.backward(dout[:, t, :])\n",
        "            grad += layer.grads[0]\n",
        "\n",
        "        self.grads[0][...] = grad\n",
        "        return None\n",
        "\n",
        "\n",
        "class TimeAffine:\n",
        "    def __init__(self, W, b):\n",
        "        self.params = [W, b]\n",
        "        self.grads = [np.zeros_like(W), np.zeros_like(b)]\n",
        "        self.x = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        N, T, D = x.shape\n",
        "        W, b = self.params\n",
        "\n",
        "        rx = x.reshape(N*T, -1)\n",
        "        out = np.dot(rx, W) + b\n",
        "        self.x = x\n",
        "        return out.reshape(N, T, -1)\n",
        "\n",
        "    def backward(self, dout):\n",
        "        x = self.x\n",
        "        N, T, D = x.shape\n",
        "        W, b = self.params\n",
        "\n",
        "        dout = dout.reshape(N*T, -1)\n",
        "        rx = x.reshape(N*T, -1)\n",
        "\n",
        "        db = np.sum(dout, axis=0)\n",
        "        dW = np.dot(rx.T, dout)\n",
        "        dx = np.dot(dout, W.T)\n",
        "        dx = dx.reshape(*x.shape)\n",
        "\n",
        "        self.grads[0][...] = dW\n",
        "        self.grads[1][...] = db\n",
        "\n",
        "        return dx\n",
        "\n",
        "\n",
        "class TimeSoftmaxWithLoss:\n",
        "    def __init__(self):\n",
        "        self.params, self.grads = [], []\n",
        "        self.cache = None\n",
        "        self.ignore_label = -1\n",
        "\n",
        "    def forward(self, xs, ts):\n",
        "        N, T, V = xs.shape\n",
        "\n",
        "        if ts.ndim == 3:  # 정답 레이블이 원핫 벡터인 경우\n",
        "            ts = ts.argmax(axis=2)\n",
        "\n",
        "        mask = (ts != self.ignore_label)\n",
        "\n",
        "        # 배치용과 시계열용을 정리(reshape)\n",
        "        xs = xs.reshape(N * T, V)\n",
        "        ts = ts.reshape(N * T)\n",
        "        mask = mask.reshape(N * T)\n",
        "\n",
        "        ys = softmax(xs)\n",
        "        ls = np.log(ys[np.arange(N * T), ts])\n",
        "        ls *= mask  # ignore_label에 해당하는 데이터는 손실을 0으로 설정\n",
        "        loss = -np.sum(ls)\n",
        "        loss /= mask.sum()\n",
        "\n",
        "        self.cache = (ts, ys, mask, (N, T, V))\n",
        "        return loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        ts, ys, mask, (N, T, V) = self.cache\n",
        "\n",
        "        dx = ys\n",
        "        dx[np.arange(N * T), ts] -= 1\n",
        "        dx *= dout\n",
        "        dx /= mask.sum()\n",
        "        dx *= mask[:, np.newaxis]  # ignore_labelㅇㅔ 해당하는 데이터는 기울기를 0으로 설정\n",
        "\n",
        "        dx = dx.reshape((N, T, V))\n",
        "\n",
        "        return dx\n",
        "\n",
        "\n",
        "class TimeDropout:\n",
        "    def __init__(self, dropout_ratio=0.5):\n",
        "        self.params, self.grads = [], []\n",
        "        self.dropout_ratio = dropout_ratio\n",
        "        self.mask = None\n",
        "        self.train_flg = True\n",
        "\n",
        "    def forward(self, xs):\n",
        "        if self.train_flg:\n",
        "            flg = np.random.rand(*xs.shape) > self.dropout_ratio\n",
        "            scale = 1 / (1.0 - self.dropout_ratio)\n",
        "            self.mask = flg.astype(np.float32) * scale\n",
        "\n",
        "            return xs * self.mask\n",
        "        else:\n",
        "            return xs\n",
        "\n",
        "    def backward(self, dout):\n",
        "        return dout * self.mask\n"
      ],
      "metadata": {
        "id": "MCDD7eqU25nV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "from common.time_layers import *\n",
        "from numpy.core.multiarray import dot\n",
        "\n",
        "class SimpleRnnlm:#4개의 Time 계층을 쌓은 신경망\n",
        "  def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
        "    V, D, H = vocab_size, wordvec_size, hidden_size\n",
        "    rn = np.random.randn\n",
        "\n",
        "    #가중치 초기화(xavier초깃값 사용)\n",
        "    embed_W = (rn(V,H)/100).astype('f')\n",
        "    rnn_Wx = (rn(D,H)/np.sqrt(D)).astype('f')\n",
        "    rnn_Wh = (rn(H,H)/np.sqrt(H)).astype('f')\n",
        "\n",
        "    rnn_b = np.zeros(H).astype('f')\n",
        "    affine_W = (rn(H,V)/np.sqrt(H)).astype('f')\n",
        "    affine_b = np.zeros(V).astype('f')\n",
        "\n",
        "    #계층 생성\n",
        "    self.layers = [\n",
        "                   TimeEmbedding(embed_W),\n",
        "                   TimeRNN(rnn_Wx, rnn_Wh, rnn_b, stateful = True),\n",
        "                   TimeAffine(affine_W, affine_b)\n",
        "\n",
        "    ]\n",
        "    self.loss_layer = TimeSoftmaxWithLoss()\n",
        "    self.rnn_layer = self.layers[1]\n",
        "\n",
        "    #모든 가중치와 기울기를 리스트에 모은다\n",
        "    self.params, self.grads = [],[]\n",
        "    for layer in self.layers:\n",
        "      self.params += layer.params\n",
        "      self.grads += layer.grads\n",
        "\n",
        "  def forward(self, xs, ts):\n",
        "    for layer in self.layers:\n",
        "      xs = layer.forward(xs)\n",
        "    loss = self.loss_layer.forward(xs,ts)\n",
        "    return loss\n",
        "  \n",
        "  def backward(self, dout = 1):\n",
        "    dout = self.loss_layer.backward(dout)\n",
        "    for layer in reversed(self.layers):\n",
        "      dout = layer.backward(dout)\n",
        "    return dout\n",
        "  \n",
        "  def reset_state(self):\n",
        "    self.rnn_layer.reset_state()\n"
      ],
      "metadata": {
        "id": "Pt3tU6KF28b7"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 언어 모델의 예측 성능 평가 척도: Perplexity(혼란도)\n",
        ": 확률의 역수(작을 수록 좋다)\n",
        "<br>\n",
        "#### 해석 방법: 분기수(number of branches)\n",
        ": 다음에 출현할 수 있는 단어의 후보 수 (최솟값: 1)"
      ],
      "metadata": {
        "id": "OYCpgnjH7aO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/DL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1wHWBZq91k6",
        "outputId": "ec923512-42a4-4f45-fe0d-626e9ae47aa7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/WegraLee/deep-learning-from-scratch-2.git original"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYyGfxxe-Sy9",
        "outputId": "25eb6d8c-c935-4c01-99a6-e468939ec39d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'original'...\n",
            "remote: Enumerating objects: 606, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 606 (delta 1), reused 5 (delta 0), pack-reused 598\u001b[K\n",
            "Receiving objects: 100% (606/606), 29.82 MiB | 13.15 MiB/s, done.\n",
            "Resolving deltas: 100% (361/361), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd original"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rRyDkgy-8Ow",
        "outputId": "8d6cf7d2-7e0f-469b-d2cf-f13ea96a1522"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/DL/original\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/drive/MyDrive/DL/original/common /content/drive/MyDrive/DL"
      ],
      "metadata": {
        "id": "3WHUoeeX_BIN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/drive/MyDrive/DL/original/dataset /content/drive/MyDrive/DL"
      ],
      "metadata": {
        "id": "JRNNk6Qw_8Qk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNNLM의 학습코드\n",
        "\n",
        "PTB 데이터셋을 이용(1000개 단어만 활용)"
      ],
      "metadata": {
        "id": "6-kgnP0H8azG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from common.optimizer import SGD\n",
        "from dataset import ptb\n"
      ],
      "metadata": {
        "id": "-X16xHJU7qu6"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#하이퍼파라미터 설정\n",
        "batch_size = 10\n",
        "wordvec_size = 100\n",
        "hidden_size = 100#RNN 은닉 상태 벡터의 원소 수\n",
        "time_size = 5#Truncated BPTT가 한 번에 펼치는 시간 크기\n",
        "lr = 0.1\n",
        "max_epoch = 100"
      ],
      "metadata": {
        "id": "rHcBn2WNABKY"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#학습 데이터 읽기(전체 중 100개만)\n",
        "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
        "corpus_size = 1000\n",
        "corpus = corpus[:corpus_size]\n",
        "vocab_size = int(max(corpus)+1)"
      ],
      "metadata": {
        "id": "42_DvW9bAmve"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs = corpus[:-1]#입력\n",
        "ts = corpus[1:]#출력(정답 레이블)\n",
        "data_size = len(xs)\n",
        "print(\"말뭉치 크기: %d, 어휘 수: %d\"%(corpus_size, vocab_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gq1-iSHCAyHg",
        "outputId": "20cc9323-9346-4fa8-c2f5-6441488d771f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "말뭉치 크기: 1000, 어휘 수: 418\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#학습시 사용하는 변수\n",
        "max_iters = data_size//(batch_size*time_size)\n",
        "time_idx = 0\n",
        "total_loss =0\n",
        "loss_count = 0\n",
        "ppl_list = []"
      ],
      "metadata": {
        "id": "HgE3O4EuA_j5"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 생성\n",
        "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)"
      ],
      "metadata": {
        "id": "4Q3QnPndBJwS"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#옵티마이저\n",
        "optimizer = SGD(lr)"
      ],
      "metadata": {
        "id": "4i8iafSSBQGd"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#각 미니 배치에서 샘플을 읽기 시작 위치를 계산\n",
        "jump = (corpus_size - 1)//batch_size\n",
        "offsets =[i*jump for i in range(batch_size)]#각 미니배치가 데이터 읽기 시작하는 위치를 계산해 offsets에 저장(각 원소에 데이터를 읽는 시작위치가 담기게 됨)"
      ],
      "metadata": {
        "id": "mLrGTz52BScR"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(max_epoch):\n",
        "  for iter in range(max_iters):\n",
        "    #미니 배치 획득(데이터를 순차적으로 읽음)\n",
        "    batch_x = np.empty((batch_size, time_size), dtype = 'i')\n",
        "    batch_t = np.empty((batch_size, time_size), dtype = 'i')\n",
        "    for t in range(time_size):\n",
        "      for i, offset in enumerate(offsets):\n",
        "        batch_x[i,t] = xs[(offset+time_idx)%data_size]\n",
        "        batch_t[i,t] = ts[(offset+time_idx)%data_size]\n",
        "      time_idx += 1\n",
        "    \n",
        "    #기울기를 구하여 매개변수 갱신\n",
        "    loss = model.forward(batch_x, batch_t)\n",
        "    model.backward()\n",
        "    optimizer.update(model.params, model.grads)\n",
        "    total_loss += loss\n",
        "    loss_count +=1\n",
        "  \n",
        "  #에폭마다 perplexity 평가\n",
        "  ppl = np.exp(total_loss/loss_count)#손실의 평균을 사용해 퍼플렉시티를 구함\n",
        "  print(\"| 에폭 %d | 퍼플렉시티 %.2f\"%(epoch+1, ppl))\n",
        "  ppl_list.append(float(ppl))\n",
        "  total_loss, loss_count = 0,0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ds4_gMZBayq",
        "outputId": "19525e73-e508-4f3e-df7c-510455a09acc"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| 에폭 1 | 퍼플렉시티 361.82\n",
            "| 에폭 2 | 퍼플렉시티 245.89\n",
            "| 에폭 3 | 퍼플렉시티 219.52\n",
            "| 에폭 4 | 퍼플렉시티 214.28\n",
            "| 에폭 5 | 퍼플렉시티 204.96\n",
            "| 에폭 6 | 퍼플렉시티 202.71\n",
            "| 에폭 7 | 퍼플렉시티 198.73\n",
            "| 에폭 8 | 퍼플렉시티 196.89\n",
            "| 에폭 9 | 퍼플렉시티 191.86\n",
            "| 에폭 10 | 퍼플렉시티 192.94\n",
            "| 에폭 11 | 퍼플렉시티 189.00\n",
            "| 에폭 12 | 퍼플렉시티 192.41\n",
            "| 에폭 13 | 퍼플렉시티 190.31\n",
            "| 에폭 14 | 퍼플렉시티 191.21\n",
            "| 에폭 15 | 퍼플렉시티 190.32\n",
            "| 에폭 16 | 퍼플렉시티 187.32\n",
            "| 에폭 17 | 퍼플렉시티 184.70\n",
            "| 에폭 18 | 퍼플렉시티 181.32\n",
            "| 에폭 19 | 퍼플렉시티 182.65\n",
            "| 에폭 20 | 퍼플렉시티 183.58\n",
            "| 에폭 21 | 퍼플렉시티 181.12\n",
            "| 에폭 22 | 퍼플렉시티 177.70\n",
            "| 에폭 23 | 퍼플렉시티 174.08\n",
            "| 에폭 24 | 퍼플렉시티 176.72\n",
            "| 에폭 25 | 퍼플렉시티 174.67\n",
            "| 에폭 26 | 퍼플렉시티 173.16\n",
            "| 에폭 27 | 퍼플렉시티 168.73\n",
            "| 에폭 28 | 퍼플렉시티 167.50\n",
            "| 에폭 29 | 퍼플렉시티 165.18\n",
            "| 에폭 30 | 퍼플렉시티 158.73\n",
            "| 에폭 31 | 퍼플렉시티 159.57\n",
            "| 에폭 32 | 퍼플렉시티 153.97\n",
            "| 에폭 33 | 퍼플렉시티 154.67\n",
            "| 에폭 34 | 퍼플렉시티 149.89\n",
            "| 에폭 35 | 퍼플렉시티 149.92\n",
            "| 에폭 36 | 퍼플렉시티 142.50\n",
            "| 에폭 37 | 퍼플렉시티 139.66\n",
            "| 에폭 38 | 퍼플렉시티 136.11\n",
            "| 에폭 39 | 퍼플렉시티 130.50\n",
            "| 에폭 40 | 퍼플렉시티 124.27\n",
            "| 에폭 41 | 퍼플렉시티 125.39\n",
            "| 에폭 42 | 퍼플렉시티 118.86\n",
            "| 에폭 43 | 퍼플렉시티 114.36\n",
            "| 에폭 44 | 퍼플렉시티 108.73\n",
            "| 에폭 45 | 퍼플렉시티 104.46\n",
            "| 에폭 46 | 퍼플렉시티 101.31\n",
            "| 에폭 47 | 퍼플렉시티 96.54\n",
            "| 에폭 48 | 퍼플렉시티 91.85\n",
            "| 에폭 49 | 퍼플렉시티 87.74\n",
            "| 에폭 50 | 퍼플렉시티 83.36\n",
            "| 에폭 51 | 퍼플렉시티 79.91\n",
            "| 에폭 52 | 퍼플렉시티 76.89\n",
            "| 에폭 53 | 퍼플렉시티 72.39\n",
            "| 에폭 54 | 퍼플렉시티 68.63\n",
            "| 에폭 55 | 퍼플렉시티 65.86\n",
            "| 에폭 56 | 퍼플렉시티 62.26\n",
            "| 에폭 57 | 퍼플렉시티 58.90\n",
            "| 에폭 58 | 퍼플렉시티 56.03\n",
            "| 에폭 59 | 퍼플렉시티 53.32\n",
            "| 에폭 60 | 퍼플렉시티 49.91\n",
            "| 에폭 61 | 퍼플렉시티 48.76\n",
            "| 에폭 62 | 퍼플렉시티 46.27\n",
            "| 에폭 63 | 퍼플렉시티 43.66\n",
            "| 에폭 64 | 퍼플렉시티 41.15\n",
            "| 에폭 65 | 퍼플렉시티 39.08\n",
            "| 에폭 66 | 퍼플렉시티 36.52\n",
            "| 에폭 67 | 퍼플렉시티 35.46\n",
            "| 에폭 68 | 퍼플렉시티 32.88\n",
            "| 에폭 69 | 퍼플렉시티 30.57\n",
            "| 에폭 70 | 퍼플렉시티 29.65\n",
            "| 에폭 71 | 퍼플렉시티 28.67\n",
            "| 에폭 72 | 퍼플렉시티 26.08\n",
            "| 에폭 73 | 퍼플렉시티 25.17\n",
            "| 에폭 74 | 퍼플렉시티 23.47\n",
            "| 에폭 75 | 퍼플렉시티 22.22\n",
            "| 에폭 76 | 퍼플렉시티 20.22\n",
            "| 에폭 77 | 퍼플렉시티 19.64\n",
            "| 에폭 78 | 퍼플렉시티 19.06\n",
            "| 에폭 79 | 퍼플렉시티 17.46\n",
            "| 에폭 80 | 퍼플렉시티 15.95\n",
            "| 에폭 81 | 퍼플렉시티 15.34\n",
            "| 에폭 82 | 퍼플렉시티 15.29\n",
            "| 에폭 83 | 퍼플렉시티 14.26\n",
            "| 에폭 84 | 퍼플렉시티 13.60\n",
            "| 에폭 85 | 퍼플렉시티 12.63\n",
            "| 에폭 86 | 퍼플렉시티 12.04\n",
            "| 에폭 87 | 퍼플렉시티 11.74\n",
            "| 에폭 88 | 퍼플렉시티 11.50\n",
            "| 에폭 89 | 퍼플렉시티 10.46\n",
            "| 에폭 90 | 퍼플렉시티 9.84\n",
            "| 에폭 91 | 퍼플렉시티 9.84\n",
            "| 에폭 92 | 퍼플렉시티 9.15\n",
            "| 에폭 93 | 퍼플렉시티 8.94\n",
            "| 에폭 94 | 퍼플렉시티 8.92\n",
            "| 에폭 95 | 퍼플렉시티 7.60\n",
            "| 에폭 96 | 퍼플렉시티 7.28\n",
            "| 에폭 97 | 퍼플렉시티 6.88\n",
            "| 에폭 98 | 퍼플렉시티 6.73\n",
            "| 에폭 99 | 퍼플렉시티 6.29\n",
            "| 에폭 100 | 퍼플렉시티 5.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title(\"Perplexity transition\")\n",
        "plt.plot(ppl_list)\n",
        "plt.ylabel(\"epoch\")\n",
        "plt.xlabel(\"perplexity\")\n",
        "plt.show()\n",
        "print(\"last perplexity: \",ppl_list[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "kXMGWwyTCTKU",
        "outputId": "423c3b90-d0ab-49e4-8ace-11fd360c3c0b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3yV9fn/8deVvSAhEFYCBgQUHEwVFRVntVqxVVtrXa0VbW3Vqt/W2qW2ftt+O6wW66YgdWNVavXn3uIIyEYEWWGFMBJIQkLG9fvj3ImHGEKAnJwk5/18PM4j9/25x7nuHMh1PuO+P+buiIiIAMRFOwAREWk/lBRERKSBkoKIiDRQUhARkQZKCiIi0kBJQUREGigpSKdjZvlm5maWsJ/nudnMHmytuKLFzPqbWZmZxTezT5mZDWzLuKR9UlKQNmNmK81sR/AHqMjMpphZRrTj2h13/193/z7sf6Ixs8vM7N3WjbBl3H21u2e4e20Qy5tm9v1G+2S4+/JoxCfti5KCtLWvuXsGMAoYA/xybw62kE7577a5b/IibaVT/ueS9s/d1wIvAocCmNlYM3vfzErMbK6Zja/fN/hme7uZvQdUAAODst+b2Udmts3MnjOz7Kbey8wyzewhM1tvZmvN7HdmFm9mSWY2x8x+HOwXb2bvmdmvg/VbzOxfwWneDn6WBDWdE8xsi5kdFvY+Pc2swsxyGr3/UOBe4Ojg2JKgfIqZ3WNmL5hZOXCimZ1pZp8E11RoZreEnae+tnKpma02s01m9ouw7UeaWUFwbJGZ/bXRcQlmdjtwHDApiGVSsI+b2aCw39fDZlZsZqvM7Jf1ibi+xmNmfzazrWa2wszOaPEHL+2fu+ulV5u8gJXAKcFyP2Ah8FsgF9gMfJXQF5VTg/WcYN83gdXAIUACkBiUrSWUVNKBp4F/BfvnAw4kBOvPAPcF+/UEPgKuDLYdCmwFhgK/AD4A4oNtt+zunEHZP4A/hq1fC/xnN9d+GfBuo7IpQClwbHDdKcB44LBg/XCgCDinUQwPAKnAcKAKGBpsnwlcHCxnAGN38/t4E/h+o1gcGBQsPww8B3QJjv0MuDzsOqqBK4B44AfAOsCi/e9Lr9Z5qaYgbe3Z4Jvyu8BbwP8CFwEvuPsL7l7n7q8ABYSSRL0p7r7Q3WvcvToom+buC9y9HPgV8M3GTTBm1is4z3XuXu7uG4E7gAsA3H0B8DvgWeBGQn9Ua1t4LVOBb5uZBesXA9P24ncB8Jy7vxdcd6W7v+nu84P1ecBjwAmNjrnV3Xe4+1xgLqHkAKE/1oPMrIe7l7n7B3sZS30T1gXAz919u7uvBP4SXFu9Ve7+QPB7mgr0AXrt7XtJ+6SkIG3tHHfPcvcD3P2H7r4DOAA4P2g6KgmSxjhCf2zqFTZxrvCyVYRqED0a7XNAUL4+7Nz3Eaox1Jsa7PeCuy9t6YW4+4eEmrPGm9nBwCBgRkuPb+IaMLOjzOyNoOmmFLiqiWvaELZcQahWAHA5MAT41Mw+NrOz9jIWgvdKJPT7rLeKUG3uS+/v7hXBYrsdMCB7Z7+G7Im0kkJC3/qvaGafph7n2y9suT+hb8qbGpUXEmpi6eHuNbs59z+A54GvmNk4d29qlNDuHic8lVBNZwMw3d0r9yL+psofBSYBZ7h7pZn9jS8nhaZPFEpo3w7a/78BTDez7nsRC4R+f9WEkuSioKw/oaY6iQGqKUh78C/ga2b2laCzN8XMxptZ3h6Ou8jMhplZGnAboT/KuzT9uPt64GXgL2bW1czizOxAMzsBwMwuBkYTaiu/BphqTQ+TLQbqgMZj+f8FfJ1QYni4mViLgDwzS9rDNXUBtgQJ4Ujgwj3s38DMLjKzHHevA0qC4rrdxNLkPQnB7+9J4HYz62JmBwDXE7pOiQFKChJ17l4ITABuJvTHtxD4H/b873Maoc7aDYQ6aa/ZzX6XAEmEvvluBaYDfcysP/A34JKgDf5RQn0ZdzQRYwVwO/Be0Aw1Niz22YS+fb/TTKyvE+pY32Bmm5rZ74fAbWa2Hfg1oT/QLXU6sNDMyoA7gQuC5rnG7gTOC0YP3dXE9h8D5cByQn0/jwKT9yIO6cDMXZPsSMdjZm8SGhkU9TuOzWwysM7d9+qeC5H2SH0KIvvBzPIJtd+PjG4kIq1DzUci+8jMfgssAP7k7iuiHY9Ia1DzkYiINFBNQUREGnToPoUePXp4fn5+tMMQEelQZs2atcndc5ra1qGTQn5+PgUFBdEOQ0SkQzGzVbvbpuYjERFpoKQgIiINlBRERKSBkoKIiDRQUhARkQZKCiIi0kBJQUREGsRkUliyYTt/fmkJm8uqoh2KiEi7EpNJYXlxGZPeWMbG7UoKIiLhYjIppCWHbuQur9rd7IwiIrEpJpNCRnI8AOU7a/ewp4hIbInJpJCWFKopVKimICKyi4glhWDy9Y/MbK6ZLTSzW4PyKWa2wszmBK8RQbmZ2V1mtszM5pnZqEjFlh4kBdUURER2FcmnpFYBJ7l7mZklAu+a2YvBtv9x9+mN9j8DGBy8jgLuCX62urSg+ahip2oKIiLhIlZT8JCyYDUxeDU3zdsE4OHguA+ALDPrE4nYMoKO5jI1H4mI7CKifQpmFm9mc4CNwCvu/mGw6fagiegOM0sOynKBwrDD1wRljc850cwKzKyguLh4n+JKTogjzqCiSs1HIiLhIpoU3L3W3UcAecCRZnYo8HPgYOAIIBv42V6e8353H+PuY3Jympw4aI/MjPSkBMrVfCQisos2GX3k7iXAG8Dp7r4+aCKqAv4JHBnsthboF3ZYXlAWEWnJ8aopiIg0EsnRRzlmlhUspwKnAp/W9xOYmQHnAAuCQ2YAlwSjkMYCpe6+PlLxpSclUKaagojILiI5+qgPMNXM4gklnyfd/Xkze93McgAD5gBXBfu/AHwVWAZUAN+NYGykJyfoPgURkUYilhTcfR4wsonyk3azvwNXRyqextKS4nWfgohIIzF5RzMENQU1H4mI7CJmk0JakjqaRUQai9mkkJGcoJvXREQaidmkkJaUQIX6FEREdhGzSSE9OZ7ynTWE+rdFRARiOCmkJSXgDpXVddEORUSk3YjZpJDeMNGO+hVEROrFblJI0pScIiKNxW5SqK8paFiqiEiDmE0KDVNyqvlIRKRBzCaFL/oUVFMQEakXw0lBfQoiIo3FblJQR7OIyJfEbFJISwo1H+muZhGRL8RsUmhoPlJHs4hIg5hNCskJccQZelKqiEiYmE0KZka6npQqIrKLmE0KEOps1n0KIiJfiFhSMLMUM/vIzOaa2UIzuzUoH2BmH5rZMjN7wsySgvLkYH1ZsD0/UrHVS0vWlJwiIuEiWVOoAk5y9+HACOB0MxsL/BG4w90HAVuBy4P9Lwe2BuV3BPtFVHpSAhVqPhIRaRCxpOAhZcFqYvBy4CRgelA+FTgnWJ4QrBNsP9nMLFLxQTCngjqaRUQaRLRPwczizWwOsBF4BfgcKHH3+q/na4DcYDkXKAQItpcC3SMZX3pSgoakioiEiWhScPdadx8B5AFHAgfv7znNbKKZFZhZQXFx8X6dKy1ZU3KKiIRrk9FH7l4CvAEcDWSZWUKwKQ9YGyyvBfoBBNszgc1NnOt+dx/j7mNycnL2K670pHg95kJEJEwkRx/lmFlWsJwKnAosJpQczgt2uxR4LlieEawTbH/dIzyBclqSagoiIuES9rzLPusDTDWzeELJ50l3f97MFgGPm9nvgE+Ah4L9HwKmmdkyYAtwQQRjAyAjOZ7ynTW4OxHu0xYR6RAilhTcfR4wsony5YT6FxqXVwLnRyqepqQlJ+AOO6prGybdERGJZTF+R7Om5BQRCRfTSUFTcoqI7Cqmk8IXs6+ppiAiAjGfFOrnaVZNQUQEYjwppGlKThGRXcR0UqivKeheBRGRkNhOCqopiIjsIraTQrKSgohIuJhOCmn19ymo+UhEBIjxpJCcEEd8nOk+BRGRQEwnBTMjLUkT7YiI1IvppACQkZygmoKISCDmk4JqCiIiX4j5pJCerCk5RUTqxXxSSEuKp0I1BRERQEmB9CTVFERE6ikpJGtKThGRekoKyfGU6Y5mERFASYG0pAQqlBRERIAIJgUz62dmb5jZIjNbaGbXBuW3mNlaM5sTvL4adszPzWyZmS0xs69EKrZw6UnxVFTXUlfnbfF2IiLtWiRnq68BbnD32WbWBZhlZq8E2+5w9z+H72xmw4ALgEOAvsCrZjbE3SPa4J+WnIA7VNbUNsyvICISqyJWU3D39e4+O1jeDiwGcps5ZALwuLtXufsKYBlwZKTiq1f/pFT1K4iItFGfgpnlAyOBD4OiH5nZPDObbGbdgrJcoDDssDU0kUTMbKKZFZhZQXFx8X7Hlh48KVX3KoiItEFSMLMM4GngOnffBtwDHAiMANYDf9mb87n7/e4+xt3H5OTk7Hd8DVNy6l4FEZHIJgUzSySUEB5x938DuHuRu9e6ex3wAF80Ea0F+oUdnheURVSXlFBSKN1RHem3EhFp9yI5+siAh4DF7v7XsPI+Ybt9HVgQLM8ALjCzZDMbAAwGPopUfPUG98wAYNG6bZF+KxGRdi+Sw22OBS4G5pvZnKDsZuDbZjYCcGAlcCWAuy80syeBRYRGLl0d6ZFHAD27ptA3M4V5a0oj/VYiIu1exJKCu78LWBObXmjmmNuB2yMV0+4cnpfF3DUlbf22IiLtTszf0QwwvF8WqzZXsLV8Z7RDERGJKiUFYHi/TADVFkQk5ikpAIflZmIGcwvVryAisU1JAeiSksiBORnMU01BRGKckkJgeNDZ7K4H44lI7FJSCIzol8mmsp2sLdkR7VBERKJGSSEwvF8WoH4FEYltSgqBg3t3JSk+Tv0KIhLTlBQCSQlxDO3blTmFSgoiEruUFMKMyMtk/tpSajULm4jEKCWFMIfnZVGxs5bPirZHOxQRkahQUghz1MBskuLjuP7JuWwqq4p2OCIibU5JIUxetzQeuHQMKzaV8c17Z7JOw1NFJMYoKTRywpAcpl1+FMXbqzj/3pm6b0FEYoqSQhOOyM/msYljKanYya+fXbDnA0REOgklhd04NDeT604ZwmufbuS1xUXRDkdEpE0oKTTjsmPzGdQzg9ueX0RldcQngRMRiTolhWYkxsdxy9cOYdXmCh58Z3m0wxERiTglhT0YN7gHXz2sN5PeWManG7ZFOxwRkYhqcVIws2PM7EIzu6T+tYf9+5nZG2a2yMwWmtm1QXm2mb1iZkuDn92CcjOzu8xsmZnNM7NR+3dprecXZw4jMS6O0//2Dhc9+CEvzl9PTW1dtMMSEWl1LUoKZjYN+DMwDjgieI3Zw2E1wA3uPgwYC1xtZsOAm4DX3H0w8FqwDnAGMDh4TQTu2btLiZzcrFReu+EEbjxtCCs2lfODR2Zz7j3vs3JTebRDExFpVdaSSWXMbDEwzPdjBhozew6YFLzGu/t6M+sDvOnuB5nZfcHyY8H+S+r32905x4wZ4wUFBfsa0j6prXOen7eOXz+3kJraOm6bcCjfGJWLmbVpHCIi+8rMZrl7k1/sW9p8tADovR8B5AMjgQ+BXmF/6DcAvYLlXKAw7LA1QVnjc000swIzKyguLt7XkPZZfJwxYUQuL157HIfkZnLDU3M59573mfzuCtaX6kY3EenYmk0KZvYfM5sB9AAWmdlLZjaj/tWSNzCzDOBp4Dp336WnNqh57FXtw93vd/cx7j4mJydnbw5tVX2zUnnsirH86qxhVOys5bbnF3H071/n+ifmUFWj4asi0jEl7GH7n/fn5GaWSCghPOLu/w6Ki8ysT1jz0cagfC3QL+zwvKCs3YqPMy4fN4DLxw3g8+Iynvi4kPvfXk7R9kruu3gMGcl7+vWKiLQvzf7Vcve3AMxsALDe3SuD9VS+aPZpkoUa2R8CFrv7X8M2zQAuBf4Q/HwurPxHZvY4cBRQ2lx/QntzYE4GN391KEN6deFnT8/jgvtn8vMzhrJsYxkL1pbSo0syPz5pEGlJX/zKC7dUsHDdNo4b3IN0JRARaQda2tFcABzj7juD9STgPXc/opljxgHvAPOB+vGbNxPqV3gS6A+sAr7p7luCJDIJOB2oAL7r7s32Ikejo7klXv+0iB8+MpvK6tBlZ6cnsbViJwN6pHPXBSMZ3CuD+99azqQ3llFVU0daUjxnHtaH44fksLZkB0uLyti4vZL+2WkM6pnBwb27ctSAbOLi1JktIvuvuY7mliaFOe4+olHZXHcf3kox7pP2mhQAlheXsWJTOYf0zaRX12Rmfr6Z65+cy+byKnpnplC4ZQdnHt6H80fn8eL8DTw/bx3lO0N9ET27JNOrawqrNpezrbIGgMNyM7npjIM5dlCPaF6WiHQCrZEUXgH+7u4zgvUJwDXufnKrRrqX2nNSaEpJxU5++ewCPt2wnV+dNYwThnzRUV5eVcPnxWUckJ1OZloiAO5OcVkVb3+2iTte+Yy1JTs4fkgO150ymFH9u0XrMkSkg2uNpHAg8AhfDBEtBC52989bLcp90NGSwv6orK5l2sxV3P3mMkoqqhk7MJsfjB/E8YN76B4JEdkr+50Uwk6UAeDuZa0U236JpaRQr7yqhsc+Ws0D7yynaFsVxw3uwa1nH8LAnIyGfWrrnMItFXxWtJ3Pi8s5qHcG44f0VJ+EiACtU1PIBH4DHB8UvQXc5u6lrRblPojFpFCvqqaWxz5czV9e/oyqmjq+f9wAUhPj+WjlFmav2trQP1FvYE46l48bwLmj8khJjI9S1CLSHrRGUnia0F3NU4Oii4Hh7v6NVotyH8RyUqi3cXsl//vfxTw7Zx0AB/fuwhH52RyWm8ngXhkM6JHOW58V8+A7K5i/tpTcrFRuPfsQThnW7IhiEenEIjX66EtlbU1J4QsrN5WTlZZIVlpSk9vdnZmfb+Y3MxaydGMZXzmkF7/52iH0zUpt40hFJNpa49lHO4L7DupPeCygB/20I/k90nebEADMjGMG9eC/1xzHT08/iLc+K+a0O97mXx+soq4u9MWgtKKaSa8v5RfPzGfm55sbykUkdrS0pjCCUNNRJmDAFuBSd58X2fCap5rCvivcUsFN/57He8s2c9SAbIb3y+KRD1ZRvrOW1MR4dlTXkpuVytkj+jJ+SA4j+3cjKUFzMol0Bq05+qgrQOMH20WLksL+cXee+LiQ2/+7mPKdNZx1eF9+MP5A8run8/KiDUyftYb3P99MbZ2TlhTPSQf35JazD6FHRnK0QxeR/dAafQrdCY0+GkfoqabvEhp9tLk1A91bSgqto6RiJ1U1dfTqmvKlbdsqq5n5+Wbe/qyY6bPW0D09ifsuHsNheZlRiFREWkNr9Ck8DhQD5wLnBctPtE54Em1ZaUlNJgSArimJfOWQ3tz+9cN4+gfHYGacd+/7PPbRasqrato4UhGJtJbWFBa4+6GNyua7+2ERi6wFVFNoe5vLqrj60dl8sHwLcQYH9e7KEfndOG90HofnZUU7PBFpgeZqCi19XvPLZnYBoaebQqi28FJrBCcdS/eMZP51+VG89/lmZq3ayiert/JUwRoenrmK4f2yuOyYA5gwPFd3T4t0UC2tKWwH0vjiEdjxQP2s9e7uXSMTXvNUU2gftlVW8/SsNUz7YBXLi8u56oQDuemMg6MdlojsRmv0KWQClwG/dfdEIB84xd27RCshSPvRNSWR7x47gNeuP4HvHNWfe9/6nMc+Wh3tsERkH7Q0KdwNjAW+HaxvJzQhjkgDM+PWsw/hhCE5/PLZBbyztBgIPeF1zdYK9mb4s4hER0v7FI5y91Fm9gmAu28NZl8T2UVCfByTLhzJ+ffO5Mpps8hOT2JtyQ7c4RujcvnTecOJV3+DSLvV0qRQbWbxhO5RwMxy+KJ/QWQXXVISmXzZEdz6n4UkJ8Rz3ug8SiqqmfL+SuLM+L9zD1dHtEg71dKkcBfwDNDTzG4nNProlxGLSjq8vlmp3Hfxrv1YmamJ3PnaUuLNuOzYfNZs3cGGbZUcN6gH+T3SoxSpiIRrUVJw90fMbBZwMqFnH53j7oubO8bMJgNnARvr73Ews1uAKwjd/AZws7u/EGz7OXA5UEtoqk8Nee1krjtlMHXu/P31ZTxRUNhQ3iUlgfsuGs0xmn9aJOr26tlHe3Vis+OBMuDhRkmhzN3/3GjfYcBjwJFAX+BVYIi77zpTTCMaktrxuDuvf7qRHdW15HVLIyk+juue+ITlxeX84dzDOW90XrRDFOn0WuPmtb3m7m+bWX4Ld58APO7uVcAKM1tGKEHMjFB4EiVmxslDd53g56mrjuHqR2Zz41NzefCd5Q3l54zM5aoTDmzrEEViWjSehfwjM5tnZpPNrFtQlgsUhu2zJij7EjObaGYFZlZQXFzc1C7SwWSmJvLP7x7Bj04cRL/sNPpnp5GSGM8fXvyUlxZuiHZ4IjElYjWF3bgH+C2hUUy/Bf4CfG9vTuDu9wP3Q6j5qLUDlOhIjI/jxq8c1LBeVVPLeffM5H+emsuwPl3pl50WxehEYkeb1hTcvcjda929DniAUBMRwFqgX9iueUGZxKjkhHjuvnAU7vDjxz5hZ41GQIu0hTZNCmbWJ2z168CCYHkGcIGZJZvZAGAw8FFbxibtT//uafzxvMOZU1jCT6fPZVNZVbRDEun0ItZ8ZGaPAeOBHma2htAkPeODqT0dWAlcCeDuC83sSWARUANcvaeRRxIbvnpYH645eTCTXl/Ky4uKuOyYfCYeP7DZ+ahFZN9FbEhqW9CQ1NjxeXEZd766lP/MW0dWaiK/OmsYXx+Zi5nujBbZW63xlFSRqDowJ4O7vj2SF645joE5GVz/5FwumfwRhVsqoh2aSKeipCAdytA+XXnqyqO5bcIhzF61lTPveof5a0qjHZZIp6GkIB1OXJxxydH5vHjt8XRJSeSihz5k4TolBpHWoKQgHVb/7mk8PnEsGckJXPTghyxevy3aIYl0eEoK0qH1y07j0SuOIiUxnu88+CErNpXv+SAR2S0lBenwDuieziPfPwqASyd/RPF23c8gsq+UFKRTGJiTwUOXjmHj9kq+N+VjyqtqACivqlGSENkLbf3sI5GIGdm/G3dfOIorHi7gG/94n1p3Pi8uA+CuC0byteF9oxyhSPunmoJ0KicP7cX/nTecmro68runcd3JQxjdvxs3PDWX2au3Rjs8kXZPdzRLp7elfCdf/8d7lFfV8MwPj9UTVyXm6Y5miWnZ6Uk8dOkRVNXUcfnUj9msB+uJ7JaSgsSEQT0zuPei0azaXMHZk97TzW4iu6GkIDHj2EE9eOqqo6mtc867Zyb/nbc+2iGJtDtKChJTDs/LYsaPj2Vony5c/ehspry3ItohibQrSgoSc3p2SeGxiWM5bVgvbvnPIqbNXBntkETaDSUFiUnJCfFMunAUpwztya+eW8ijH66Odkgi7YKSgsSspIQ47v7OKE48KIebn5nP3W8so66u4w7RFmkNSgoS05IT4rnnotGceXgf/vTSEiZOm0XpjupohyUSNRFLCmY22cw2mtmCsLJsM3vFzJYGP7sF5WZmd5nZMjObZ2ajIhWXSGMpifFM+vZIfn3WMN5cspGzJ73Lxyu3RDsskaiIZE1hCnB6o7KbgNfcfTDwWrAOcAYwOHhNBO6JYFwiX2JmfG/cAJ64cizVNXWcf+9Mrn50tqb7lJgTsaTg7m8Djb9uTQCmBstTgXPCyh/2kA+ALDPrE6nYRHZn9AHZvHrDCVx78mBeW1zEyX99i39q2KrEkLbuU+jl7vV3DG0AegXLuUBh2H5rgjKRNpeWlMBPTh3CGzeO5/jBPbj1P4u4ZcZCatUJLTEgah3NHnoS317/LzOziWZWYGYFxcXFEYhMJKRPZir3XTyGK44bwJT3VzLx4YKGeRpEOqu2TgpF9c1Cwc+NQflaoF/YfnlB2Ze4+/3uPsbdx+Tk5EQ0WJH4OOMXZw7jt+ccyhtLNnL+vTNZX7oj2mGJRExbJ4UZwKXB8qXAc2HllwSjkMYCpWHNTCJRd/HYA3josiNYvaWCc+5+j/lr9EA96ZwiOST1MWAmcJCZrTGzy4E/AKea2VLglGAd4AVgObAMeAD4YaTiEtlXJx7Uk+k/OJqEuDi+eZ8eqCedkybZEdlLxduruHJaAbNXl3DJ0Qdw81eHkpIYH+2wRFpMk+yItKKcLsk8PvForjhuAA/PXMU3/vE+y4O5oEU6OiUFkX2QlBDHL84cxkOXjmFd6Q7OnvQeLy/cEO2wRPabkoLIfjh5aC/+e81xDMxJZ+K0Wfzl5SW6n0E6NCUFkf2Um5XKk1cezfmj8/j768u4ZPKHrNpcHu2wRPaJkoJIK0hJjOf/zjuc33/jMOYWlnLaHW9z9xvL2FlTF+3QRPaKkoJIKzEzvn1kf169/gROHtqTP720hNPvfJuXF26gI4/yk9iipCDSynpnpvCP74xm8mVjwGHitFl8674PmFNYEu3QRPZISUEkQk46uBcv/eR4fnfOoSzfVMa597zP5HdXqNYg7ZqSgkgEJcbHcdHYA3jjxvGcfHBPbnt+ETc+NY/K6tpohybSJCUFkTbQJSWRey8azbUnD+bp2Wv41n0zWbFJI5Sk/VFSEGkjcXHGT04dwr0XjWbFpnLOuPNtpr6/kjrd1yDtiJKCSBs7/dDevPyTEzhqQHd+M2MhFz74AfPWqBNa2gclBZEo6J2ZwpTvHsHvv3EYi9dv5+xJ73H5lI+VHCTqlBREoqT+voZ3f3YiN542hIJVWzl70nvc/Mx8tldWRzs8iVFKCiJR1iUlkR+dNJh3f3YiVxw3gMc/Ws1pd7zN658WRTs0iUFKCiLtRJeURH5x5jCe/sExZCQn8L0pBVz9yGxN/yltSklBpJ0Z2b8bz18zjutPHcKri4s4+S9vcd9bn+s5StImlBRE2qHkhHiuOXkwr15/AkcP7M7vX/yUE//8Jk8WFFJTq+QgkaOkINKO9ctO46HLjmDq944kOz2Jn06fx2l/e5tnP1mr5CAREZU5ms1sJbAdqAVq3H2MmWUDTwD5wErgm+6+tbnzaI5miSXuzksLi7jjlc9YUrSd/O5p/PDEQXx9ZC6J8fp+Jy3XXudoPtHdR8y3TNYAAA3NSURBVIQFdhPwmrsPBl4L1kUkYGacfmhvXrz2OO69aDTpyQn8dPo8vvb3d5m1aku0w5NOoj19vZgATA2WpwLnRDEWkXYrLi6UHJ7/8TjuvWgU23ZUc+49M7np6Xks21imx2bIfolW89EKYCvgwH3ufr+Zlbh7VrDdgK31642OnQhMBOjfv//oVatWtWHkIu1PeVUNd762lIfeXUFtndMlOYFDczM5ZVgvvnVEPzKSE6IdorQzzTUfRSsp5Lr7WjPrCbwC/BiYEZ4EzGyru3dr7jzqUxD5wurNFXywYjPz1pQwe1UJi9Zvo0tKAhce2Z/Ljs2nT2ZqtEOUdqK5pBCVrxDuvjb4udHMngGOBIrMrI+7rzezPsDGaMQm0lH1755G/+5pfHNMPwDmFJbwwDvLeeCd5Ux+bwVfH5nLlSccyIE5GVGOVNqzNq8pmFk6EOfu24PlV4DbgJOBze7+BzO7Cch29582dy7VFET2rHBLBQ++s5zHPy5kZ20dXxnWm4knDGRU/2Yr4tKJtavmIzMbCDwTrCYAj7r77WbWHXgS6A+sIjQktdkhFUoKIi23qayKKe+tZNoHqyjdUc2YA7rxvXEDOGVoL5IS2tOYE4m0dpUUWpOSgsjeK6+q4cmCQh56dwVrtu6gW1oiE0bkcv6YPA7pmxnt8KQNKCmIyJfU1Nbx7rJNTJ+1hpcXFbGzpo5xg3pw5QkDGTeoB6FBgNIZKSmISLNKK6p57OPVTH53BRu3VzEwJ51R/btxSN+ujOzfjeF5mUoSnYiSgoi0SFVNLc9+spb/zt/AonWlbCrbCcDwvEx+MP5ATh3Wm/g4JYeOTklBRPbJxm2VvLK4iPvfXs6qzRUM7JHOxUcfwLmj8+iakhjt8GQfKSmIyH6prXNeXLCeB99ZwZzCEtKS4jl7eF9G9e/GoF4ZDO6ZQRcliQ5DSUFEWs38NaVM+2Al/5m7nh3VtQ3luVmpDO3ThaF9ujJhRF8G9ewSxSilOUoKItLqauucwi0VfFa0naUby/h0w3aWbNjG58Xl1NY5pw3rxVXjD2Rkvyx1Urcz7e4xFyLS8cXHGfk90snvkc5ph3xRvrmsiqkzVzH1/ZW8vKiIbmmJDOqZwaCeXThqQDYnHtSTzDQ1NbVXqimISESUV9Xw3Jx1LFhXyrKiMpYUbad0RzXxccaR+dmMG9yD0Qd0Y3heFqlJ8dEON6aopiAibS49OYELj+rfsF5X58xdU8Kri4t4ddFG/vTSEgAS4owjB2Rzzshczji0tzqso0w1BRGJiq3lO/mkcCsfr9zKi/PXs3JzBckJcYzol0WfzBR6ZabQu2sKvYLXgB7pZKcnRTvsTkEdzSLSrrk7cwpLePaTtSxct40N2yrZuK2KnbV1DfuYweG5mYw/qCfjD8rh8Lws3Ui3j5QURKTDcXe2VlSzobSSom2VLFhbyhtLNvJJYQnukJmayLhBPThqYDZ53VLpk5lKj4xkEuMNMyMpPk59FbuhpCAincaW8p28s7SYd5du4p2lm9iwrXK3++Z1S2Von64M7dOV/tlp9M1KIS8rjdxuqTFdy1BHs4h0GtnpSUwYkcuEEbm4Oxu2VbK+tJINpZVsKquits6pc6ioqmFJ0XYWrd/Gq4uLCP/+m5IYx+CeXTiodxfyuqWG+i4yU8hKTaRLSgIZyYmkJceTlhhPQnxszTWhpCAiHZaZ0SczdY/zT1dW17KhtJK1JTso3FLB0o1lfFa0nbc/K6a4rIrmGkySEuLIzUplWJ+uDOvblQNz0kPvmZVCZuoXI6US4+KI6wS1DyUFEen0UhLjG260a2xnTR0bt4f6LbbtqGF7VQ3bK6upqKqlYmctFTtrWLW5gnlrS/jv/PW7fY+EOKNvVip53VLp1TWF1KR4UhPjSUqIwwh1lKclJTCiXxYj+2eRltQ+//y2z6hERNpIUkIced3SyOuWtsd9t1VWs3pzBetKdrC+tJKyqpqGbWVVNazduoM1Wyv4eOUWKqvrqKyupaqmtqEmUlMXWkiIMw7q3YXs9CS6poSarDLTEslKTSIrLZHkhDiSEuJITognMzWR7PQkstOTyExNjHhfiJKCiEgLdU1J5NDcTA7N3bdpS7dVVjN71VY+XrmFBWu3UbqjmnUlO9hWWUNpRfUuQ3B3H0MC3dKTuHjsAXz/uIH7FEdz2l1SMLPTgTuBeOBBd/9DlEMSEWkVXVMSg/ssen5pm7uzo7qWkopqqmrqqK4N1TRKd1SzpXwnW8p3srWimtKK0M8eGckRibFdJQUziwfuBk4F1gAfm9kMd18U3chERCLLzEhLSoh6X0N7G2t1JLDM3Ze7+07gcWBClGMSEYkZ7S0p5AKFYetrgrIGZjbRzArMrKC4uLhNgxMR6ezaW1LYI3e/393HuPuYnJycaIcjItKptLeksBboF7aeF5SJiEgbaG9J4WNgsJkNMLMk4AJgRpRjEhGJGe1q9JG715jZj4CXCA1JnezuC6MclohIzGhXSQHA3V8AXoh2HCIisai9NR+JiEgUdej5FMysGFi1j4f3ADa1YjgdRSxedyxeM8TmdcfiNcPeX/cB7t7k8M0OnRT2h5kV7G6Sic4sFq87Fq8ZYvO6Y/GaoXWvW81HIiLSQElBREQaxHJSuD/aAURJLF53LF4zxOZ1x+I1Qyted8z2KYiIyJfFck1BREQaUVIQEZEGMZkUzOx0M1tiZsvM7KZoxxMJZtbPzN4ws0VmttDMrg3Ks83sFTNbGvzsFu1YI8HM4s3sEzN7PlgfYGYfBp/5E8GztToNM8sys+lm9qmZLTazo2PhszaznwT/vheY2WNmltIZP2szm2xmG81sQVhZk5+vhdwVXP88Mxu1N+8Vc0khbHa3M4BhwLfNbFh0o4qIGuAGdx8GjAWuDq7zJuA1dx8MvBasd0bXAovD1v8I3OHug4CtwOVRiSpy7gT+n7sfDAwndO2d+rM2s1zgGmCMux9K6HlpF9A5P+spwOmNynb3+Z4BDA5eE4F79uaNYi4pECOzu7n7enefHSxvJ/RHIpfQtU4NdpsKnBOdCCPHzPKAM4EHg3UDTgKmB7t0qus2s0zgeOAhAHff6e4lxMBnTej5balmlgCkAevphJ+1u78NbGlUvLvPdwLwsId8AGSZWZ+WvlcsJoU9zu7W2ZhZPjAS+BDo5e7rg00bgF5RCiuS/gb8FKgL1rsDJe5eE6x3ts98AFAM/DNoMnvQzNLp5J+1u68F/gysJpQMSoFZdO7POtzuPt/9+hsXi0khpphZBvA0cJ27bwvf5qHxyJ1qTLKZnQVsdPdZ0Y6lDSUAo4B73H0kUE6jpqJO+ll3I/SteADQF0jny00sMaE1P99YTAoxM7ubmSUSSgiPuPu/g+Ki+qpk8HNjtOKLkGOBs81sJaGmwZMItbdnBU0M0Pk+8zXAGnf/MFifTihJdPbP+hRghbsXu3s18G9Cn39n/qzD7e7z3a+/cbGYFGJidregHf0hYLG7/zVs0wzg0mD5UuC5to4tktz95+6e5+75hD7b1939O8AbwHnBbp3qut19A1BoZgcFRScDi+jknzWhZqOxZpYW/Huvv+5O+1k3srvPdwZwSTAKaSxQGtbMtEcxeUezmX2VULtz/exut0c5pFZnZuOAd4D5fNG2fjOhfoUngf6EHjv+TXdv3IHVKZjZeOBGdz/LzAYSqjlkA58AF7l7VTTja01mNoJQx3oSsBz4LqEvfZ36szazW4FvERpt9wnwfULt553qszazx4DxhB6RXQT8BniWJj7fIEFOItSUVgF8190LWvxesZgURESkabHYfCQiIruhpCAiIg2UFEREpIGSgoiINFBSEBGRBkoKIq3IzMbXP5l1H469yswuCZYvM7O+rRudyJ4l7HkXEQlnZglhz9ZpNe5+b9jqZcACYF1rv49Ic1RTkJhkZvnB3AOPBPMPTA/ujB1tZm+Z2SwzeynsMQJvmtnfzKwAuNbMppjZvWZWYGafBc9cavwe6cFz8D8KHlQ3ISi/08x+HSx/xczeNrM4M7vFzG40s/OAMcAjZjbHzM40s2fDznuqmT3TJr8oiTlKChLLDgL+4e5DgW3A1cDfgfPcfTQwGQi/2z3J3ce4+1+C9XxCj2I/E7jXzFIanf8XhB6zcSRwIvCn4OmlPwe+ZWYnAncRuuO0/q5z3H06UAB8x91HAC8AB5tZTrDLd4PYRFqdmo8klhW6+3vB8r8IPQbkUOCV0JMCiCf0SOZ6TzQ6/sngj/lSM1sOHNxo+2mEHs53Y7CeAvR398VmdgXwNvATd/+8uSDd3c1sGnCRmf0TOBq4ZG8uVKSllBQkljV+xst2YKG7H72b/cv3cHzjdQPOdfclTZzrMGAzoUc+t8Q/gf8AlcBTkejTEAE1H0ls629m9QngQuADIKe+zMwSzeyQZo4/P+gLOBAYCDT+4/8S8OPgAWWY2cjg5wHADYQmPjrDzI5q4tzbgS71K+6+jlCn8y8JJQiRiFBSkFi2hNDc1YuBbgT9CcAfzWwuMAc4ppnjVwMfAS8CV7l7ZaPtvwUSgXlmthD4bdgjzW8M/tBfDjzYRH/EFEL9FHPMLDUoe4RQk9diRCJET0mVmBRMUfp8MOH7vhw/JTh++p72bS1mNgn4xN0faqv3lNijPgWRDsDMZhHq07gh2rFI56aagoiINFCfgoiINFBSEBGRBkoKIiLSQElBREQaKCmIiEiD/w9sQUNiXgfi/gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "last perplexity:  5.891688240554667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNNLM의 Trainer 클래스 (책 내에 구현)\n",
        "\n",
        "1. 미니배치를 '순차적'으로 만들어\n",
        "2. 모델의 순전파와 역전파를 호출하고\n",
        "3. 옵티마이저로 가중치를 갱신하고\n",
        "4. 퍼플렉시티를 구합니다"
      ],
      "metadata": {
        "id": "qyd7HdLgFtzE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from common.trainer import RnnlmTrainer"
      ],
      "metadata": {
        "id": "dPUGLQfvFR8b"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
        "optimizer = SGD(lr)\n",
        "trainer = RnnlmTrainer(model, optimizer)\n",
        "\n",
        "trainer.fit(xs,ts,max_epoch, batch_size, time_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivGz-5z0F3Si",
        "outputId": "69ee3033-29eb-4670-e958-a382d2b10a88"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| 에폭 1 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 417.94\n",
            "| 에폭 2 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 384.71\n",
            "| 에폭 3 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 263.79\n",
            "| 에폭 4 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 219.64\n",
            "| 에폭 5 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 208.87\n",
            "| 에폭 6 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 206.94\n",
            "| 에폭 7 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 200.01\n",
            "| 에폭 8 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 199.70\n",
            "| 에폭 9 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 194.16\n",
            "| 에폭 10 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 190.44\n",
            "| 에폭 11 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 191.63\n",
            "| 에폭 12 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 189.64\n",
            "| 에폭 13 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 193.11\n",
            "| 에폭 14 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 186.77\n",
            "| 에폭 15 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 185.98\n",
            "| 에폭 16 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 190.13\n",
            "| 에폭 17 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 188.41\n",
            "| 에폭 18 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 183.73\n",
            "| 에폭 19 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 180.31\n",
            "| 에폭 20 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 180.86\n",
            "| 에폭 21 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 177.97\n",
            "| 에폭 22 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 178.22\n",
            "| 에폭 23 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 180.07\n",
            "| 에폭 24 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 174.87\n",
            "| 에폭 25 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 170.36\n",
            "| 에폭 26 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 174.99\n",
            "| 에폭 27 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 169.60\n",
            "| 에폭 28 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 168.32\n",
            "| 에폭 29 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 164.27\n",
            "| 에폭 30 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 161.96\n",
            "| 에폭 31 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 158.56\n",
            "| 에폭 32 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 154.28\n",
            "| 에폭 33 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 152.01\n",
            "| 에폭 34 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 151.82\n",
            "| 에폭 35 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 144.74\n",
            "| 에폭 36 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 142.47\n",
            "| 에폭 37 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 145.82\n",
            "| 에폭 38 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 133.46\n",
            "| 에폭 39 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 132.56\n",
            "| 에폭 40 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 125.40\n",
            "| 에폭 41 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 119.02\n",
            "| 에폭 42 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 119.97\n",
            "| 에폭 43 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 115.95\n",
            "| 에폭 44 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 111.22\n",
            "| 에폭 45 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 102.59\n",
            "| 에폭 46 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 99.74\n",
            "| 에폭 47 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 98.74\n",
            "| 에폭 48 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 93.44\n",
            "| 에폭 49 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 89.12\n",
            "| 에폭 50 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 82.09\n",
            "| 에폭 51 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 81.28\n",
            "| 에폭 52 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 77.05\n",
            "| 에폭 53 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 74.61\n",
            "| 에폭 54 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 69.46\n",
            "| 에폭 55 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 65.42\n",
            "| 에폭 56 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 63.20\n",
            "| 에폭 57 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 62.18\n",
            "| 에폭 58 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 56.80\n",
            "| 에폭 59 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 53.13\n",
            "| 에폭 60 |  반복 1 / 19 | 시간 7[s] | 퍼플렉서티 50.62\n",
            "| 에폭 61 |  반복 1 / 19 | 시간 7[s] | 퍼플렉서티 47.22\n",
            "| 에폭 62 |  반복 1 / 19 | 시간 7[s] | 퍼플렉서티 44.78\n",
            "| 에폭 63 |  반복 1 / 19 | 시간 7[s] | 퍼플렉서티 43.17\n",
            "| 에폭 64 |  반복 1 / 19 | 시간 7[s] | 퍼플렉서티 40.34\n",
            "| 에폭 65 |  반복 1 / 19 | 시간 7[s] | 퍼플렉서티 37.30\n",
            "| 에폭 66 |  반복 1 / 19 | 시간 7[s] | 퍼플렉서티 36.55\n",
            "| 에폭 67 |  반복 1 / 19 | 시간 7[s] | 퍼플렉서티 34.67\n",
            "| 에폭 68 |  반복 1 / 19 | 시간 7[s] | 퍼플렉서티 32.60\n",
            "| 에폭 69 |  반복 1 / 19 | 시간 7[s] | 퍼플렉서티 30.87\n",
            "| 에폭 70 |  반복 1 / 19 | 시간 8[s] | 퍼플렉서티 28.76\n",
            "| 에폭 71 |  반복 1 / 19 | 시간 8[s] | 퍼플렉서티 27.23\n",
            "| 에폭 72 |  반복 1 / 19 | 시간 8[s] | 퍼플렉서티 25.29\n",
            "| 에폭 73 |  반복 1 / 19 | 시간 8[s] | 퍼플렉서티 23.99\n",
            "| 에폭 74 |  반복 1 / 19 | 시간 8[s] | 퍼플렉서티 22.85\n",
            "| 에폭 75 |  반복 1 / 19 | 시간 8[s] | 퍼플렉서티 21.56\n",
            "| 에폭 76 |  반복 1 / 19 | 시간 8[s] | 퍼플렉서티 20.55\n",
            "| 에폭 77 |  반복 1 / 19 | 시간 8[s] | 퍼플렉서티 19.27\n",
            "| 에폭 78 |  반복 1 / 19 | 시간 8[s] | 퍼플렉서티 18.33\n",
            "| 에폭 79 |  반복 1 / 19 | 시간 8[s] | 퍼플렉서티 17.01\n",
            "| 에폭 80 |  반복 1 / 19 | 시간 9[s] | 퍼플렉서티 16.16\n",
            "| 에폭 81 |  반복 1 / 19 | 시간 9[s] | 퍼플렉서티 15.29\n",
            "| 에폭 82 |  반복 1 / 19 | 시간 9[s] | 퍼플렉서티 14.39\n",
            "| 에폭 83 |  반복 1 / 19 | 시간 9[s] | 퍼플렉서티 13.96\n",
            "| 에폭 84 |  반복 1 / 19 | 시간 9[s] | 퍼플렉서티 13.43\n",
            "| 에폭 85 |  반복 1 / 19 | 시간 9[s] | 퍼플렉서티 12.62\n",
            "| 에폭 86 |  반복 1 / 19 | 시간 9[s] | 퍼플렉서티 12.15\n",
            "| 에폭 87 |  반복 1 / 19 | 시간 9[s] | 퍼플렉서티 12.15\n",
            "| 에폭 88 |  반복 1 / 19 | 시간 9[s] | 퍼플렉서티 10.77\n",
            "| 에폭 89 |  반복 1 / 19 | 시간 10[s] | 퍼플렉서티 10.25\n",
            "| 에폭 90 |  반복 1 / 19 | 시간 10[s] | 퍼플렉서티 10.22\n",
            "| 에폭 91 |  반복 1 / 19 | 시간 10[s] | 퍼플렉서티 9.41\n",
            "| 에폭 92 |  반복 1 / 19 | 시간 10[s] | 퍼플렉서티 8.90\n",
            "| 에폭 93 |  반복 1 / 19 | 시간 10[s] | 퍼플렉서티 9.55\n",
            "| 에폭 94 |  반복 1 / 19 | 시간 10[s] | 퍼플렉서티 8.49\n",
            "| 에폭 95 |  반복 1 / 19 | 시간 10[s] | 퍼플렉서티 7.77\n",
            "| 에폭 96 |  반복 1 / 19 | 시간 10[s] | 퍼플렉서티 7.86\n",
            "| 에폭 97 |  반복 1 / 19 | 시간 10[s] | 퍼플렉서티 7.08\n",
            "| 에폭 98 |  반복 1 / 19 | 시간 10[s] | 퍼플렉서티 6.68\n",
            "| 에폭 99 |  반복 1 / 19 | 시간 11[s] | 퍼플렉서티 6.39\n",
            "| 에폭 100 |  반복 1 / 19 | 시간 11[s] | 퍼플렉서티 6.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8OX2Tr0cGFP2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}